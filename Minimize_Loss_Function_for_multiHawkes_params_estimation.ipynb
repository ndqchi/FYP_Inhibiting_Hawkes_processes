{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZpqxf8Of6WT"
      },
      "outputs": [],
      "source": [
        "from math import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "\n",
        "class hawkes():\n",
        "    def __init__(self, nbr, T, mu, alpha, beta):\n",
        "        self.nbr = nbr\n",
        "        self.T = T\n",
        "        self.mu = mu\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.count = np.zeros(self.nbr, dtype = \"int\")\n",
        "        self.jtimes = [[] for _ in range(nbr)]\n",
        "\n",
        "    def calculate(self, s):\n",
        "        lambdam = [self.mu for _ in range(self.nbr)]\n",
        "        for m in range(self.nbr):\n",
        "            for n in range(self.nbr):\n",
        "                for k in range(self.count[n]):\n",
        "                    lambdam[m] += self.alpha[n][m] * exp(-self.beta*(s-self.jtimes[n][k]))\n",
        "        return lambdam\n",
        "\n",
        "    def simulate(self):\n",
        "        s = 0.0\n",
        "        while s < self.T:\n",
        "            lambdabar = sum(self.calculate(s))\n",
        "\n",
        "            u = np.random.uniform()\n",
        "            w = -log(u)/lambdabar\n",
        "            s += w\n",
        "\n",
        "            lambdams = self.calculate(s)\n",
        "            lambdabars = sum(lambdams)\n",
        "\n",
        "            k = None\n",
        "            D = np.random.uniform()\n",
        "            if D <= lambdabars/lambdabar:\n",
        "                lambdamk = 0.0\n",
        "                for k in range(nbr):\n",
        "                    if (lambdamk < D*lambdabar and D*lambdabar <= lambdamk + lambdams[k]):\n",
        "                        break\n",
        "                    lambdamk += lambdams[k]\n",
        "                self.count[k] += 1\n",
        "                self.jtimes[k].append(s)\n",
        "            if k is not None and self.jtimes[k][self.count[k] - 1] > self.T:\n",
        "                self.count[k] -= 1\n",
        "                self.jtimes[k].pop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbr = 2\n",
        "\n",
        "sample_size = 10**4\n",
        "sample_mean = [0 for _ in range(nbr)]\n",
        "sample_var = [0 for _ in range(nbr)]\n",
        "sample_covar = [0 for _ in range(nbr - 1)]\n",
        "\n",
        "w = 10\n",
        "b = 50\n",
        "t = 0.1\n",
        "\n",
        "alpha = [[0, -w], [w, 0]]\n",
        "beta = b\n",
        "mu = 250\n",
        "n1 = []\n",
        "n2 = []\n",
        "for i in range(sample_size):\n",
        "    eg1 = hawkes(nbr = 2, T = t, mu = mu, alpha = alpha, beta = beta)\n",
        "    eg1.simulate()\n",
        "    for j in range(nbr):\n",
        "      sample_mean[j] += eg1.count[j]\n",
        "      sample_var[j] += (eg1.count[j]**2)\n",
        "    n1.append(eg1.count[0])\n",
        "    n2.append(eg1.count[1])\n",
        "      \n",
        "\n",
        "for j in range(nbr):\n",
        "    sample_mean[j] /= (sample_size*1.0)\n",
        "    sample_var[j] -= ((sample_mean[j]**2)*sample_size)\n",
        "    sample_var[j] /= ((sample_size - 1)*1.0)\n",
        "\n",
        "for i in range(sample_size):\n",
        "    sample_covar[0] += ((n1[i] - sample_mean[0])*(n2[i] - sample_mean[1]))\n",
        "\n",
        "sample_covar[0] /= (sample_size-1)\n",
        "\n",
        "print(sample_covar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v27_LSsNgB7T",
        "outputId": "adc6a3fd-ec22-4c32-cb51-a86f0f3391bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.3286884888488852]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0, 0]\n",
        "var = [0, 0]\n",
        "covar = [0]\n",
        "mean[0] = (((0.250e3 * b * b * w - 0.500e3 * b * w * w - 0.250e3 * pow(w, 0.3e1)) * cos(w * t) + (-0.250e3 * b * b * w - 0.500e3 * b * w * w + 0.250e3 * pow(w, 0.3e1)) * sin(w * t)) * exp(-0.1e1 * b * t) + (0.250e3 * b * t + 0.250e3) * pow(w, 0.3e1) + (0.250e3 * b * b * t + 0.500e3 * b) * w * w + (0.250e3 * pow(b, 0.3e1) * t - 0.250e3 * b * b) * w + 0.250e3 * pow(b, 0.4e1) * t) * pow(b * b + w * w, -0.2e1)\n",
        "mean[1] = (((-0.250e3 * b * b * w - 0.500e3 * b * w * w + 0.250e3 * pow(w, 0.3e1)) * cos(w * t) + (-0.250e3 * b * b * w + 0.500e3 * b * w * w + 0.250e3 * pow(w, 0.3e1)) * sin(w * t)) * exp(-0.1e1 * b * t) + (-0.250e3 * b * t - 0.250e3) * pow(w, 0.3e1) + (0.250e3 * b * b * t + 0.500e3 * b) * w * w + (-0.250e3 * pow(b, 0.3e1) * t + 0.250e3 * b * b) * w + 0.250e3 * pow(b, 0.4e1) * t) * pow(b * b + w * w, -0.2e1)\n",
        "var[0] = ((((0.2250e4 + 0.2250e4 * b * t) * pow(w, 0.9e1) + (0.6750e4 * b * b * t + 0.2750e4 * b) * pow(w, 0.8e1) + (0.4750e4 * pow(b, 0.3e1) * t + 0.9250e4 * b * b) * pow(w, 0.7e1) + (0.5250e4 * pow(b, 0.4e1) * t + 0.10250e5 * pow(b, 0.3e1)) * pow(w, 0.6e1) + (0.2750e4 * pow(b, 0.5e1) * t + 0.3250e4 * pow(b, 0.4e1)) * pow(w, 0.5e1) + (-0.9750e4 * pow(b, 0.5e1) - 0.1750e4 * pow(b, 0.6e1) * t) * pow(w, 0.4e1) + (-0.4250e4 * pow(b, 0.6e1) + 0.250e3 * pow(b, 0.7e1) * t) * pow(w, 0.3e1) + (-0.1250e4 * pow(b, 0.7e1) - 0.250e3 * pow(b, 0.8e1) * t) * w * w - 0.500e3 * pow(b, 0.8e1) * w) * sin(w * t) + ((0.750e3 + 0.2250e4 * b * t) * pow(w, 0.9e1) - 0.2250e4 * b * b * t * pow(w, 0.8e1) + (-0.500e3 * b * b - 0.4250e4 * pow(b, 0.3e1) * t) * pow(w, 0.7e1) + (-0.9000e4 * pow(b, 0.3e1) - 0.4750e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (-0.17000e5 * pow(b, 0.4e1) - 0.7250e4 * pow(b, 0.5e1) * t) * pow(w, 0.5e1) + (-0.2750e4 * pow(b, 0.6e1) * t - 0.10000e5 * pow(b, 0.5e1)) * pow(w, 0.4e1) + (-0.750e3 * pow(b, 0.7e1) * t + 0.500e3 * pow(b, 0.6e1)) * pow(w, 0.3e1) + (-0.1000e4 * pow(b, 0.7e1) - 0.250e3 * pow(b, 0.8e1) * t) * w * w + 0.250e3 * pow(b, 0.8e1) * w) * cos(w * t)) * exp(-0.1e1 * b * t) + ((-0.125e3 * pow(b, 0.6e1) * pow(w, 0.3e1) + 0.500e3 * pow(b, 0.4e1) * pow(w, 0.5e1) + 0.3875e4 * b * b * pow(w, 0.7e1) - 0.750e3 * pow(w, 0.9e1)) * cos(0.2e1 * w * t) + (0.625e3 * pow(b, 0.5e1) * pow(w, 0.4e1) + 0.1750e4 * pow(b, 0.3e1) * pow(w, 0.6e1) - 0.2875e4 * b * pow(w, 0.8e1)) * sin(0.2e1 * w * t) - 0.2375e4 * pow(b, 0.3e1) * pow(w, 0.6e1) - 0.1125e4 * b * pow(w, 0.8e1) - 0.125e3 * pow(b, 0.7e1) * w * w - 0.1375e4 * pow(b, 0.5e1) * pow(w, 0.4e1)) * exp(-0.2e1 * b * t) + 0.1125e4 * b * pow(w, 0.8e1) + (-0.3375e4 * b * b - 0.2250e4 * pow(b, 0.3e1) * t) * pow(w, 0.7e1) + (0.11375e5 * pow(b, 0.3e1) + 0.2250e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (0.16500e5 * pow(b, 0.4e1) - 0.250e3 * pow(b, 0.5e1) * t) * pow(w, 0.5e1) + (0.11375e5 * pow(b, 0.5e1) + 0.4750e4 * pow(b, 0.6e1) * t) * pow(w, 0.4e1) + (-0.375e3 * pow(b, 0.6e1) + 0.2250e4 * pow(b, 0.7e1) * t) * pow(w, 0.3e1) + (0.1125e4 * pow(b, 0.7e1) + 0.2750e4 * pow(b, 0.8e1) * t) * w * w + (-0.250e3 * pow(b, 0.8e1) + 0.250e3 * pow(b, 0.9e1) * t) * w + 0.250e3 * pow(b, 0.10e2) * t) / (pow(b, 0.4e1) + 0.2e1 * b * b * w * w + pow(w, 0.4e1)) * pow(b * b + w * w, -0.2e1) / (b * b + 0.9e1 * w * w)\n",
        "var[1] = ((((0.2250e4 + 0.2250e4 * b * t) * pow(w, 0.9e1) + (-0.6750e4 * b * b * t - 0.2750e4 * b) * pow(w, 0.8e1) + (0.4750e4 * pow(b, 0.3e1) * t + 0.9250e4 * b * b) * pow(w, 0.7e1) + (-0.5250e4 * pow(b, 0.4e1) * t - 0.10250e5 * pow(b, 0.3e1)) * pow(w, 0.6e1) + (0.2750e4 * pow(b, 0.5e1) * t + 0.3250e4 * pow(b, 0.4e1)) * pow(w, 0.5e1) + (0.1750e4 * pow(b, 0.6e1) * t + 0.9750e4 * pow(b, 0.5e1)) * pow(w, 0.4e1) + (-0.4250e4 * pow(b, 0.6e1) + 0.250e3 * pow(b, 0.7e1) * t) * pow(w, 0.3e1) + (0.250e3 * pow(b, 0.8e1) * t + 0.1250e4 * pow(b, 0.7e1)) * w * w - 0.500e3 * pow(b, 0.8e1) * w) * sin(w * t) + ((-0.750e3 - 0.2250e4 * b * t) * pow(w, 0.9e1) - 0.2250e4 * b * b * t * pow(w, 0.8e1) + (0.4250e4 * pow(b, 0.3e1) * t + 0.500e3 * b * b) * pow(w, 0.7e1) + (-0.9000e4 * pow(b, 0.3e1) - 0.4750e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (0.7250e4 * pow(b, 0.5e1) * t + 0.17000e5 * pow(b, 0.4e1)) * pow(w, 0.5e1) + (-0.2750e4 * pow(b, 0.6e1) * t - 0.10000e5 * pow(b, 0.5e1)) * pow(w, 0.4e1) + (0.750e3 * pow(b, 0.7e1) * t - 0.500e3 * pow(b, 0.6e1)) * pow(w, 0.3e1) + (-0.1000e4 * pow(b, 0.7e1) - 0.250e3 * pow(b, 0.8e1) * t) * w * w - 0.250e3 * pow(b, 0.8e1) * w) * cos(w * t)) * exp(-0.1e1 * b * t) + ((0.125e3 * pow(b, 0.6e1) * pow(w, 0.3e1) - 0.500e3 * pow(b, 0.4e1) * pow(w, 0.5e1) - 0.3875e4 * b * b * pow(w, 0.7e1) + 0.750e3 * pow(w, 0.9e1)) * cos(0.2e1 * w * t) + (-0.625e3 * pow(b, 0.5e1) * pow(w, 0.4e1) - 0.1750e4 * pow(b, 0.3e1) * pow(w, 0.6e1) + 0.2875e4 * b * pow(w, 0.8e1)) * sin(0.2e1 * w * t) - 0.2375e4 * pow(b, 0.3e1) * pow(w, 0.6e1) - 0.1125e4 * b * pow(w, 0.8e1) - 0.125e3 * pow(b, 0.7e1) * w * w - 0.1375e4 * pow(b, 0.5e1) * pow(w, 0.4e1)) * exp(-0.2e1 * b * t) + 0.1125e4 * b * pow(w, 0.8e1) + (0.3375e4 * b * b + 0.2250e4 * pow(b, 0.3e1) * t) * pow(w, 0.7e1) + (0.11375e5 * pow(b, 0.3e1) + 0.2250e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (-0.16500e5 * pow(b, 0.4e1) + 0.250e3 * pow(b, 0.5e1) * t) * pow(w, 0.5e1) + (0.11375e5 * pow(b, 0.5e1) + 0.4750e4 * pow(b, 0.6e1) * t) * pow(w, 0.4e1) + (0.375e3 * pow(b, 0.6e1) - 0.2250e4 * pow(b, 0.7e1) * t) * pow(w, 0.3e1) + (0.1125e4 * pow(b, 0.7e1) + 0.2750e4 * pow(b, 0.8e1) * t) * w * w + (0.250e3 * pow(b, 0.8e1) - 0.250e3 * pow(b, 0.9e1) * t) * w + 0.250e3 * pow(b, 0.10e2) * t) / (pow(b, 0.4e1) + 0.2e1 * b * b * w * w + pow(w, 0.4e1)) * pow(b * b + w * w, -0.2e1) / (b * b + 0.9e1 * w * w)\n",
        "covar[0] = ((((-0.2250e4 * b * t - 0.1500e4) * pow(w, 0.9e1) + (-0.750e3 * b * b + 0.4250e4 * pow(b, 0.3e1) * t) * pow(w, 0.7e1) + (0.16750e5 * pow(b, 0.4e1) + 0.7250e4 * pow(b, 0.5e1) * t) * pow(w, 0.5e1) + (-0.250e3 * pow(b, 0.6e1) + 0.750e3 * pow(b, 0.7e1) * t) * pow(w, 0.3e1) - 0.250e3 * pow(b, 0.8e1) * w) * sin(w * t) + ((0.4000e4 * b + 0.6750e4 * b * b * t) * pow(w, 0.8e1) + (0.13000e5 * pow(b, 0.3e1) + 0.5250e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (-0.8000e4 * pow(b, 0.5e1) - 0.1750e4 * pow(b, 0.6e1) * t) * pow(w, 0.4e1) + (-0.1000e4 * pow(b, 0.7e1) - 0.250e3 * pow(b, 0.8e1) * t) * w * w) * cos(w * t)) * exp(-0.1e1 * b * t) + 0.125e3 * w * ((0.6e1 * pow(w, 0.8e1) + 0.1e1 * pow(b, 0.6e1) * w * w - 0.4e1 * pow(b, 0.4e1) * pow(w, 0.4e1) - 0.31e2 * pow(w, 0.6e1) * b * b) * sin(0.2e1 * w * t) + (0.14e2 * pow(w, 0.5e1) * pow(b, 0.3e1) - 0.23e2 * pow(w, 0.7e1) * b + 0.5e1 * pow(b, 0.5e1) * pow(w, 0.3e1)) * cos(0.2e1 * w * t)) * exp(-0.2e1 * b * t) - 0.1125e4 * b * pow(w, 0.8e1) + (-0.14750e5 * pow(b, 0.3e1) - 0.4500e4 * pow(b, 0.4e1) * t) * pow(w, 0.6e1) + (0.7375e4 * pow(b, 0.5e1) - 0.5000e4 * pow(b, 0.6e1) * t) * pow(w, 0.4e1) + (0.1000e4 * pow(b, 0.7e1) - 0.500e3 * pow(b, 0.8e1) * t) * w * w) * pow(b * b + w * w, -0.3e1) / (pow(b, 0.4e1) + 0.10e2 * b * b * w * w + 0.9e1 * pow(w, 0.4e1))"
      ],
      "metadata": {
        "id": "by0Z_sMpgCjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_mean)\n",
        "print(mean)\n",
        "print(sample_var)\n",
        "print(var)\n",
        "print(sample_covar)\n",
        "print(covar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uWPM_w_gGvB",
        "outputId": "65419b5b-83dd-45e4-8191-d40b40c8dadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[28.3742, 20.3211]\n",
            "[28.3231580858621, 20.48065255256024]\n",
            "[27.225496909691124, 20.77987277727764]\n",
            "[27.561190372772554, 20.24516825245136]\n",
            "[-1.3286884888488852]\n",
            "[-1.1443026131197649]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "def loss_function(params):\n",
        "    b = params[0]\n",
        "    w = params[1]\n",
        "    t = 0.1\n",
        "    return np.square(-sample_mean[0] + (((0.250e3 * b * b * w - 0.500e3 * b * w * w - 0.250e3 * np.power(w, 0.3e1)) * np.cos(w * t) + (-0.250e3 * b * b * w - 0.500e3 * b * w * w + 0.250e3 * np.power(w, 0.3e1)) * np.sin(w * t)) * np.exp(-0.1e1 * b * t) + (0.250e3 * b * t + 0.250e3) * np.power(w, 0.3e1) + (0.250e3 * b * b * t + 0.500e3 * b) * w * w + (0.250e3 * np.power(b, 0.3e1) * t - 0.250e3 * b * b) * w + 0.250e3 * np.power(b, 0.4e1) * t) * np.power(b * b + w * w, -0.2e1))\n",
        "    np.square(-sample_mean[1] + (((-0.250e3 * b * b * w - 0.500e3 * b * w * w + 0.250e3 * np.power(w, 0.3e1)) * np.cos(w * t) + (-0.250e3 * b * b * w + 0.500e3 * b * w * w + 0.250e3 * np.power(w, 0.3e1)) * np.sin(w * t)) * np.exp(-0.1e1 * b * t) + (-0.250e3 * b * t - 0.250e3) * np.power(w, 0.3e1) + (0.250e3 * b * b * t + 0.500e3 * b) * w * w + (-0.250e3 * np.power(b, 0.3e1) * t + 0.250e3 * b * b) * w + 0.250e3 * np.power(b, 0.4e1) * t) * np.power(b * b + w * w, -0.2e1))\n",
        "    np.square(-sample_var[0] + ((((0.2250e4 + 0.2250e4 * b * t) * np.power(w, 0.9e1) + (0.6750e4 * b * b * t + 0.2750e4 * b) * np.power(w, 0.8e1) + (0.4750e4 * np.power(b, 0.3e1) * t + 0.9250e4 * b * b) * np.power(w, 0.7e1) + (0.5250e4 * np.power(b, 0.4e1) * t + 0.10250e5 * np.power(b, 0.3e1)) * np.power(w, 0.6e1) + (0.2750e4 * np.power(b, 0.5e1) * t + 0.3250e4 * np.power(b, 0.4e1)) * np.power(w, 0.5e1) + (-0.9750e4 * np.power(b, 0.5e1) - 0.1750e4 * np.power(b, 0.6e1) * t) * np.power(w, 0.4e1) + (-0.4250e4 * np.power(b, 0.6e1) + 0.250e3 * np.power(b, 0.7e1) * t) * np.power(w, 0.3e1) + (-0.1250e4 * np.power(b, 0.7e1) - 0.250e3 * np.power(b, 0.8e1) * t) * w * w - 0.500e3 * np.power(b, 0.8e1) * w) * np.sin(w * t) + ((0.750e3 + 0.2250e4 * b * t) * np.power(w, 0.9e1) - 0.2250e4 * b * b * t * np.power(w, 0.8e1) + (-0.500e3 * b * b - 0.4250e4 * np.power(b, 0.3e1) * t) * np.power(w, 0.7e1) + (-0.9000e4 * np.power(b, 0.3e1) - 0.4750e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (-0.17000e5 * np.power(b, 0.4e1) - 0.7250e4 * np.power(b, 0.5e1) * t) * np.power(w, 0.5e1) + (-0.2750e4 * np.power(b, 0.6e1) * t - 0.10000e5 * np.power(b, 0.5e1)) * np.power(w, 0.4e1) + (-0.750e3 * np.power(b, 0.7e1) * t + 0.500e3 * np.power(b, 0.6e1)) * np.power(w, 0.3e1) + (-0.1000e4 * np.power(b, 0.7e1) - 0.250e3 * np.power(b, 0.8e1) * t) * w * w + 0.250e3 * np.power(b, 0.8e1) * w) * np.cos(w * t)) * np.exp(-0.1e1 * b * t) + ((-0.125e3 * np.power(b, 0.6e1) * np.power(w, 0.3e1) + 0.500e3 * np.power(b, 0.4e1) * np.power(w, 0.5e1) + 0.3875e4 * b * b * np.power(w, 0.7e1) - 0.750e3 * np.power(w, 0.9e1)) * np.cos(0.2e1 * w * t) + (0.625e3 * np.power(b, 0.5e1) * np.power(w, 0.4e1) + 0.1750e4 * np.power(b, 0.3e1) * np.power(w, 0.6e1) - 0.2875e4 * b * np.power(w, 0.8e1)) * np.sin(0.2e1 * w * t) - 0.2375e4 * np.power(b, 0.3e1) * np.power(w, 0.6e1) - 0.1125e4 * b * np.power(w, 0.8e1) - 0.125e3 * np.power(b, 0.7e1) * w * w - 0.1375e4 * np.power(b, 0.5e1) * np.power(w, 0.4e1)) * np.exp(-0.2e1 * b * t) + 0.1125e4 * b * np.power(w, 0.8e1) + (-0.3375e4 * b * b - 0.2250e4 * np.power(b, 0.3e1) * t) * np.power(w, 0.7e1) + (0.11375e5 * np.power(b, 0.3e1) + 0.2250e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (0.16500e5 * np.power(b, 0.4e1) - 0.250e3 * np.power(b, 0.5e1) * t) * np.power(w, 0.5e1) + (0.11375e5 * np.power(b, 0.5e1) + 0.4750e4 * np.power(b, 0.6e1) * t) * np.power(w, 0.4e1) + (-0.375e3 * np.power(b, 0.6e1) + 0.2250e4 * np.power(b, 0.7e1) * t) * np.power(w, 0.3e1) + (0.1125e4 * np.power(b, 0.7e1) + 0.2750e4 * np.power(b, 0.8e1) * t) * w * w + (-0.250e3 * np.power(b, 0.8e1) + 0.250e3 * np.power(b, 0.9e1) * t) * w + 0.250e3 * np.power(b, 0.10e2) * t) / (np.power(b, 0.4e1) + 0.2e1 * b * b * w * w + np.power(w, 0.4e1)) * np.power(b * b + w * w, -0.2e1) / (b * b + 0.9e1 * w * w))\n",
        "    np.square(-sample_var[1] + ((((0.2250e4 + 0.2250e4 * b * t) * np.power(w, 0.9e1) + (-0.6750e4 * b * b * t - 0.2750e4 * b) * np.power(w, 0.8e1) + (0.4750e4 * np.power(b, 0.3e1) * t + 0.9250e4 * b * b) * np.power(w, 0.7e1) + (-0.5250e4 * np.power(b, 0.4e1) * t - 0.10250e5 * np.power(b, 0.3e1)) * np.power(w, 0.6e1) + (0.2750e4 * np.power(b, 0.5e1) * t + 0.3250e4 * np.power(b, 0.4e1)) * np.power(w, 0.5e1) + (0.1750e4 * np.power(b, 0.6e1) * t + 0.9750e4 * np.power(b, 0.5e1)) * np.power(w, 0.4e1) + (-0.4250e4 * np.power(b, 0.6e1) + 0.250e3 * np.power(b, 0.7e1) * t) * np.power(w, 0.3e1) + (0.250e3 * np.power(b, 0.8e1) * t + 0.1250e4 * np.power(b, 0.7e1)) * w * w - 0.500e3 * np.power(b, 0.8e1) * w) * np.sin(w * t) + ((-0.750e3 - 0.2250e4 * b * t) * np.power(w, 0.9e1) - 0.2250e4 * b * b * t * np.power(w, 0.8e1) + (0.4250e4 * np.power(b, 0.3e1) * t + 0.500e3 * b * b) * np.power(w, 0.7e1) + (-0.9000e4 * np.power(b, 0.3e1) - 0.4750e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (0.7250e4 * np.power(b, 0.5e1) * t + 0.17000e5 * np.power(b, 0.4e1)) * np.power(w, 0.5e1) + (-0.2750e4 * np.power(b, 0.6e1) * t - 0.10000e5 * np.power(b, 0.5e1)) * np.power(w, 0.4e1) + (0.750e3 * np.power(b, 0.7e1) * t - 0.500e3 * np.power(b, 0.6e1)) * np.power(w, 0.3e1) + (-0.1000e4 * np.power(b, 0.7e1) - 0.250e3 * np.power(b, 0.8e1) * t) * w * w - 0.250e3 * np.power(b, 0.8e1) * w) * np.cos(w * t)) * np.exp(-0.1e1 * b * t) + ((0.125e3 * np.power(b, 0.6e1) * np.power(w, 0.3e1) - 0.500e3 * np.power(b, 0.4e1) * np.power(w, 0.5e1) - 0.3875e4 * b * b * np.power(w, 0.7e1) + 0.750e3 * np.power(w, 0.9e1)) * np.cos(0.2e1 * w * t) + (-0.625e3 * np.power(b, 0.5e1) * np.power(w, 0.4e1) - 0.1750e4 * np.power(b, 0.3e1) * np.power(w, 0.6e1) + 0.2875e4 * b * np.power(w, 0.8e1)) * np.sin(0.2e1 * w * t) - 0.2375e4 * np.power(b, 0.3e1) * np.power(w, 0.6e1) - 0.1125e4 * b * np.power(w, 0.8e1) - 0.125e3 * np.power(b, 0.7e1) * w * w - 0.1375e4 * np.power(b, 0.5e1) * np.power(w, 0.4e1)) * np.exp(-0.2e1 * b * t) + 0.1125e4 * b * np.power(w, 0.8e1) + (0.3375e4 * b * b + 0.2250e4 * np.power(b, 0.3e1) * t) * np.power(w, 0.7e1) + (0.11375e5 * np.power(b, 0.3e1) + 0.2250e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (-0.16500e5 * np.power(b, 0.4e1) + 0.250e3 * np.power(b, 0.5e1) * t) * np.power(w, 0.5e1) + (0.11375e5 * np.power(b, 0.5e1) + 0.4750e4 * np.power(b, 0.6e1) * t) * np.power(w, 0.4e1) + (0.375e3 * np.power(b, 0.6e1) - 0.2250e4 * np.power(b, 0.7e1) * t) * np.power(w, 0.3e1) + (0.1125e4 * np.power(b, 0.7e1) + 0.2750e4 * np.power(b, 0.8e1) * t) * w * w + (0.250e3 * np.power(b, 0.8e1) - 0.250e3 * np.power(b, 0.9e1) * t) * w + 0.250e3 * np.power(b, 0.10e2) * t) / (np.power(b, 0.4e1) + 0.2e1 * b * b * w * w + np.power(w, 0.4e1)) * np.power(b * b + w * w, -0.2e1) / (b * b + 0.9e1 * w * w))\n",
        "    np.square(-sample_covar[0] + ((((-0.2250e4 * b * t - 0.1500e4) * np.power(w, 0.9e1) + (-0.750e3 * b * b + 0.4250e4 * np.power(b, 0.3e1) * t) * np.power(w, 0.7e1) + (0.16750e5 * np.power(b, 0.4e1) + 0.7250e4 * np.power(b, 0.5e1) * t) * np.power(w, 0.5e1) + (-0.250e3 * np.power(b, 0.6e1) + 0.750e3 * np.power(b, 0.7e1) * t) * np.power(w, 0.3e1) - 0.250e3 * np.power(b, 0.8e1) * w) * np.sin(w * t) + ((0.4000e4 * b + 0.6750e4 * b * b * t) * np.power(w, 0.8e1) + (0.13000e5 * np.power(b, 0.3e1) + 0.5250e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (-0.8000e4 * np.power(b, 0.5e1) - 0.1750e4 * np.power(b, 0.6e1) * t) * np.power(w, 0.4e1) + (-0.1000e4 * np.power(b, 0.7e1) - 0.250e3 * np.power(b, 0.8e1) * t) * w * w) * np.cos(w * t)) * np.exp(-0.1e1 * b * t) + 0.125e3 * w * ((0.6e1 * np.power(w, 0.8e1) + 0.1e1 * np.power(b, 0.6e1) * w * w - 0.4e1 * np.power(b, 0.4e1) * np.power(w, 0.4e1) - 0.31e2 * np.power(w, 0.6e1) * b * b) * np.sin(0.2e1 * w * t) + (0.14e2 * np.power(w, 0.5e1) * np.power(b, 0.3e1) - 0.23e2 * np.power(w, 0.7e1) * b + 0.5e1 * np.power(b, 0.5e1) * np.power(w, 0.3e1)) * np.cos(0.2e1 * w * t)) * np.exp(-0.2e1 * b * t) - 0.1125e4 * b * np.power(w, 0.8e1) + (-0.14750e5 * np.power(b, 0.3e1) - 0.4500e4 * np.power(b, 0.4e1) * t) * np.power(w, 0.6e1) + (0.7375e4 * np.power(b, 0.5e1) - 0.5000e4 * np.power(b, 0.6e1) * t) * np.power(w, 0.4e1) + (0.1000e4 * np.power(b, 0.7e1) - 0.500e3 * np.power(b, 0.8e1) * t) * w * w) * np.power(b * b + w * w, -0.3e1) / (np.power(b, 0.4e1) + 0.10e2 * b * b * w * w + 0.9e1 * np.power(w, 0.4e1)))\n",
        "\n",
        "solvers = [\"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"Newton-CG\", \"L-BFGS-B\", \"TNC\",\n",
        "           \"COBYLA\", \"SLSQP\", \"trust-constr\", \"dogleg\", \"trust-ncg\", \"trust-exact\",\n",
        "           \"trust-krylov\"]\n",
        "solvers_with_bounds = [\"Nelder-Mead\", \"L-BFGS-B\", \"TNC\", \"SLSQP\", \"Powell\", \"trust-constr\"]\n",
        "for solver in solvers:\n",
        "  try:\n",
        "    result = minimize(loss_function, # given function\n",
        "        x0=[50, 10], # ranges of each parameter\n",
        "        method=solver,\n",
        "    )\n",
        "  except:\n",
        "    continue\n",
        "  if result[\"success\"]:\n",
        "    print(solver+ \" solver succeeded: \")\n",
        "    print(\"Real values:  [50, 10]\")\n",
        "    print(\"Parameters estimated: [\" + ', '.join(\"{:.4f}\".format(a) for a in result[\"x\"])+ \"]\")\n",
        "    print(\"Loss function value: \" + '{:.2e}'.format(result[\"fun\"]))\n",
        "    print()\n",
        "  # else:\n",
        "  #   print(solver+\" failed\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw-BrA67js9H",
        "outputId": "cc02b60f-e5bd-4d38-d63d-6539b1e90a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nelder-Mead solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [50.0480, 10.2069]\n",
            "Loss function value: 1.39e-24\n",
            "\n",
            "Powell solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [48.7640, 9.9999]\n",
            "Loss function value: 1.14e-28\n",
            "\n",
            "CG solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9692, 10.1941]\n",
            "Loss function value: 5.40e-11\n",
            "\n",
            "BFGS solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9692, 10.1941]\n",
            "Loss function value: 1.58e-11\n",
            "\n",
            "L-BFGS-B solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9693, 10.1942]\n",
            "Loss function value: 7.99e-11\n",
            "\n",
            "TNC solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.5631, 10.1286]\n",
            "Loss function value: 1.58e-19\n",
            "\n",
            "COBYLA solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9904, 10.1977]\n",
            "Loss function value: 1.28e-09\n",
            "\n",
            "SLSQP solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9694, 10.1934]\n",
            "Loss function value: 4.20e-08\n",
            "\n",
            "trust-constr solver succeeded: \n",
            "Real values:  [50, 10]\n",
            "Parameters estimated: [49.9692, 10.1941]\n",
            "Loss function value: 4.42e-16\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################### for neural network modeling\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "## hyper parameters\n",
        "time_step = 20 # truncation depth of RNN \n",
        "size_rnn = 64 # the number of units in the RNN\n",
        "size_nn = 64 # the nubmer of units in each hidden layer in the cumulative hazard function network\n",
        "size_layer_chfn = 2 # the number of the hidden layers in the cumulative hazard function network\n",
        "\n",
        "## mean and std of the log of the inter-event interval, which will be used for the data standardization\n",
        "mu = np.log(np.ediff1d(T_train)).mean()\n",
        "sigma = np.log(np.ediff1d(T_train)).std()\n",
        "\n",
        "## kernel initializer for positive weights\n",
        "def abs_glorot_uniform(shape, dtype=None, partition_info=None): \n",
        "    return K.abs(keras.initializers.glorot_uniform(seed=None)(shape,dtype=dtype))\n",
        "\n",
        "## Inputs \n",
        "inputs  = layers.Input(shape=(niter, 5)) # input to RNN (event history)\n",
        "elapsed_time = layers.Input(shape=(1,)) # input to cumulative hazard function network (the elapsed time from the most recent event)\n",
        "\n",
        "## log-transformation and standardization\n",
        "event_history_nmlz = layers.Lambda(lambda x: (K.log(x)-mu)/sigma )(event_history)\n",
        "elapsed_time_nmlz = layers.Lambda(lambda x: (K.log(x)-mu)/sigma )(elapsed_time) \n",
        "\n",
        "## RNN\n",
        "output_rnn = layers.SimpleRNN(size_rnn,input_shape=(time_step,1),activation='tanh')(event_history_nmlz)\n",
        "\n",
        "## the first hidden layer in the cummulative hazard function network\n",
        "hidden_tau = layers.Dense(size_nn,kernel_initializer=abs_glorot_uniform,kernel_constraint=keras.constraints.NonNeg(),use_bias=False)(elapsed_time_nmlz) # elapsed time -> the 1st hidden layer, positive weights\n",
        "hidden_rnn = layers.Dense(size_nn)(output_rnn) # rnn output -> the 1st hidden layer\n",
        "hidden = layers.Lambda(lambda inputs: K.tanh(inputs[0]+inputs[1]) )([hidden_tau,hidden_rnn])\n",
        "\n",
        "## the second and higher hidden layers\n",
        "for i in range(size_layer_chfn-1):\n",
        "    hidden = layers.Dense(size_nn,activation='tanh',kernel_initializer=abs_glorot_uniform,kernel_constraint=keras.constraints.NonNeg())(hidden) # positive weights\n",
        "\n",
        "## Outputs\n",
        "Int_l = layers.Dense(1, activation='softplus',kernel_initializer=abs_glorot_uniform, kernel_constraint=keras.constraints.NonNeg() )(hidden) # cumulative hazard function, positive weights\n",
        "l = layers.Lambda( lambda inputs: K.gradients(inputs[0],inputs[1])[0] )([Int_l,elapsed_time]) # hazard function\n",
        "\n",
        "## define model\n",
        "model = Model(inputs=inputs, outputs=[w, b])\n",
        "model.add_loss( -K.mean( K.log( 1e-10 + l ) - Int_l ) ) # set loss function to be the negative log-likelihood function"
      ],
      "metadata": {
        "id": "kCf32tECgaEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dT_train = np.ediff1d(T_train) # transform a series of timestamps to a series of interevent intervals: T_train -> dT_train\n",
        "n = dT_train.shape[0]\n",
        "input_RNN = np.array( [ dT_train[i:i+time_step] for i in range(n-time_step) ]).reshape(n-time_step,time_step,1)\n",
        "input_CHFN = dT_train[-n+time_step:].reshape(n-time_step,1)\n",
        "\n",
        "## training \n",
        "model.compile(keras.optimizers.Adam(lr=0.001))\n",
        "model.fit([input_RNN,input_CHFN], epochs=10, batch_size=256, validation_split=0.2) # In our study, we have set epochs = 100 and employed early stopping. Please see code.ipynb for more details."
      ],
      "metadata": {
        "id": "n85l-IYLj15m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}